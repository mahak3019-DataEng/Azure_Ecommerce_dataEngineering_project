{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a068bcba-462f-4d54-a23c-e11a61c116ee",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import split\n",
    "dbutils.widgets.text(\"silver_table\",\"\")\n",
    "dbutils.widgets.text(\"silver_schema\",\"\")\n",
    "dbutils.widgets.text(\"bronze_schema\",\"\")\n",
    "dbutils.widgets.text(\"bronze_table\",\"\")\n",
    "dbutils.widgets.text(\"loadID\",\"\")\n",
    "dbutils.widgets.text(\"env\",\"\")\n",
    "dbutils.widgets.text(\"transformation_type\",\"\")\n",
    "silver_table = dbutils.widgets.get(\"silver_table\").strip().split(\".\")[1]\n",
    "silver_schema = dbutils.widgets.get(\"silver_schema\").strip()\n",
    "bronze_schema = dbutils.widgets.get(\"bronze_schema\").strip()\n",
    "bronze_table = dbutils.widgets.get(\"bronze_table\").strip().split(\".\")[1]\n",
    "loadID = dbutils.widgets.get(\"loadID\").strip()\n",
    "env = dbutils.widgets.get(\"env\").strip()\n",
    "transformation_type = dbutils.widgets.get(\"transformation_type\").strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "beba242e-eed2-41f4-8e22-7defba4c3e8c",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "spark.sql(f\"use hive_metastore.{env}_bronze\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a33c4daf-1eba-4c5b-8d73-5223ef469528",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df = spark.sql(f\" select * from {bronze_schema}.{bronze_table} WHERE loadID = '{loadID}'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8bd13df6-7eec-429e-b4fd-4eb0a028359e",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.types import DecimalType, IntegerType, StringType, BooleanType, FloatType\n",
    "from pyspark.sql.functions import expr, when, col, upper, regexp_replace, round, year, current_date, concat, lit, initcap, avg "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2eef79d4-41e4-4c58-b2c5-184290a9e43b",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.types import DecimalType, IntegerType, StringType, BooleanType, FloatType\n",
    "from pyspark.sql.functions import expr, when, col, upper, regexp_replace, round, year, current_date, concat, lit\n",
    "def users_transformation(users_df):\n",
    "    users_df = users_df.withColumn(\"countryCode\", upper(col(\"countryCode\")))\n",
    "    # Normalizing country value for all the tables\n",
    "    users_df = users_df.withColumn(\"country\", initcap(col(\"country\")))\n",
    "\n",
    "    # Handling multiple languages elegantly with `expr` and `case when`\n",
    "    users_df = users_df.withColumn(\"language_full\", expr(\"case \\\n",
    "                                                     when language = 'en' then 'English' \\\n",
    "                                                     when language = 'fr' then 'French' \\\n",
    "                                                     else 'Other' end\"))\n",
    "    # Correcting potential data entry errors in `gender` column\n",
    "    users_df = users_df.withColumn(\"gender\", when(col(\"gender\")=='M', 'MALE') \\\n",
    "                                       .when(col(\"gender\")=='F', 'FEMALE') \\\n",
    "                                           .otherwise('Other'))\n",
    "    \n",
    "    # Using `regexp_replace` to clean `civilitytitle` values\n",
    "    users_df = users_df.withColumn(\"civilitytitle_clean\", regexp_replace(regexp_replace(col(\"civilitytitle\"), \"(mrs|miss)\", \"Ms\"), \"mr\", \"Mr\"))\n",
    "\n",
    "    # Derive new column `years_since_last_login` from `dayssincelastlogin`\n",
    "    users_df = users_df.withColumn(\"years_since_last_login\", round(col(\"dayssincelastlogin\")/365,2)).withColumn(\"years_since_last_login\", col(\"years_since_last_login\").cast(DecimalType(10, 2)))\n",
    "\n",
    "    # Calculate age of account in years and categorize into `account_age_group`\n",
    "    users_df = users_df.withColumn(\"account_age_group\", round(col(\"seniority\")/365,2))\n",
    "\n",
    "    users_df = users_df.withColumn(\n",
    "    \"account_age_group\",\n",
    "    when(col(\"account_age_group\") < 4, \"New\") \\\n",
    "    .when((col(\"account_age_group\") >= 4) & (col(\"account_age_group\") <= 8), \"Intermediate\") \\\n",
    "    .otherwise(\"Experienced\"))\n",
    "\n",
    "    # Add a column with the current year for comparison\n",
    "    users_df = users_df.withColumn(\"current_year\", year(current_date()))\n",
    "\n",
    "    # Creatively combining strings to form a unique user descriptor\n",
    "    users_df = users_df.withColumn(\"user_descriptor\", \\\n",
    "                             concat(col(\"gender\"), lit(\"_\"), \\\n",
    "                                    col(\"countrycode\"), lit(\"_\"), \\\n",
    "                                    expr(\"substring(civilitytitle_clean, 0, 3)\"), lit(\"_\"), \\\n",
    "                                    col(\"language_full\")))\n",
    "    # change the remaining data types\n",
    "    users_df = users_df.withColumn(\"hasanyapp\", col(\"hasanyapp\").cast(BooleanType()))\n",
    "    users_df = users_df.withColumn(\"hasandroidapp\", col(\"hasandroidapp\").cast(BooleanType()))\n",
    "    users_df = users_df.withColumn(\"hasiosapp\", col(\"hasiosapp\").cast(BooleanType()))\n",
    "    users_df = users_df.withColumn(\"hasprofilepicture\", col(\"hasprofilepicture\").cast(BooleanType()))\n",
    "\n",
    "\n",
    "    users_df = users_df.withColumn(\"socialnbfollowers\", col(\"socialnbfollowers\").cast(IntegerType()))\n",
    "    users_df = users_df.withColumn(\"socialnbfollows\", col(\"socialnbfollows\").cast(IntegerType()))\n",
    "\n",
    "    users_df = users_df.withColumn(\"productspassrate\", col(\"productspassrate\").cast(DecimalType(10, 2)))\n",
    "    users_df = users_df.withColumn(\"seniorityasmonths\", col(\"seniorityasmonths\").cast(DecimalType(10, 2)))\n",
    "    users_df = users_df.withColumn(\"seniorityasyears\", col(\"seniorityasyears\").cast(DecimalType(10, 2)))\n",
    "\n",
    "    users_df = users_df.withColumn(\"dayssincelastlogin\", when(col(\"dayssincelastlogin\").isNotNull(), col(\"dayssincelastlogin\").cast(IntegerType())).otherwise(0))\n",
    "    return users_df\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "32292892-ce0b-42ae-9653-215898623a99",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.types import DecimalType, IntegerType, StringType, BooleanType, FloatType\n",
    "from pyspark.sql.functions import expr, when, col, upper, regexp_replace, round, year, current_date, concat, lit\n",
    "def buyers_transformation(buyers_df):\n",
    "    # Casting Integer columns\n",
    "    integer_columns = [\n",
    "    'buyers', 'topbuyers', 'femalebuyers', 'malebuyers',\n",
    "    'topfemalebuyers', 'topmalebuyers', 'totalproductsbought',\n",
    "    'totalproductswished', 'totalproductsliked', 'toptotalproductsbought',\n",
    "    'toptotalproductswished', 'toptotalproductsliked'\n",
    "    ]\n",
    "\n",
    "    for column_name in integer_columns:\n",
    "        buyers_df = buyers_df.withColumn(column_name, col(column_name).cast(IntegerType()))\n",
    "        buyers_df = buyers_df.fillna({column_name:0})\n",
    "\n",
    "    # Casting Decimal columns\n",
    "    decimal_columns = [\n",
    "    'topbuyerratio', 'femalebuyersratio', 'topfemalebuyersratio',\n",
    "    'boughtperwishlistratio', 'boughtperlikeratio', 'topboughtperwishlistratio',\n",
    "    'topboughtperlikeratio', 'meanproductsbought', 'meanproductswished',\n",
    "    'meanproductsliked', 'topmeanproductsbought', 'topmeanproductswished',\n",
    "    'topmeanproductsliked', 'meanofflinedays', 'topmeanofflinedays',\n",
    "    'meanfollowers', 'meanfollowing', 'topmeanfollowers', 'topmeanfollowing'\n",
    "    ]\n",
    "\n",
    "    for column_name in decimal_columns:\n",
    "        buyers_df = buyers_df.withColumn(column_name, col(column_name).cast(DecimalType(10, 2)))\n",
    "        buyers_df = buyers_df.fillna({column_name:0})\n",
    "    \n",
    "    # Normalize country column values for all tables\n",
    "    buyers_df = buyers_df.withColumn(\"country\", initcap(col(\"country\")))\n",
    "\n",
    "    # Calculate the ratio of female to male buyers\n",
    "    buyers_df = buyers_df.withColumn(\"female_to_male_ratio\", round(col(\"femalebuyers\")/(col(\"malebuyers\")+1),2)).withColumn(\"female_to_male_ratio\", col(\"female_to_male_ratio\").cast(DecimalType(10, 2)))\n",
    "\n",
    "    # Determine the market potential by comparing wishlist and purchases\n",
    "    buyers_df = buyers_df.withColumn(\"wishlist_to_purchase_ratio\", \n",
    "                               round(col(\"totalproductswished\") / (col(\"totalproductsbought\") + 1), 2)).withColumn(\"wishlist_to_purchase_ratio\", col(\"wishlist_to_purchase_ratio\").cast(DecimalType(10, 2)))\n",
    "\n",
    "    # Tag countries with a high engagement ratio\n",
    "    high_engagement_threshold = 0.5\n",
    "    buyers_df = buyers_df.withColumn(\"high_engagement\",\n",
    "                               when(col(\"boughtperwishlistratio\") > high_engagement_threshold, True)\n",
    "                               .otherwise(False))\n",
    "                               \n",
    "    # Flag markets with increasing female buyer participation\n",
    "    buyers_df = buyers_df.withColumn(\"growing_female_market\",\n",
    "                               when(col(\"femalebuyersratio\") > col(\"topfemalebuyersratio\"), True)\n",
    "                               .otherwise(False))\n",
    "    \n",
    "    return buyers_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d740b44e-a170-4dad-bf35-f6c87744d581",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.types import DecimalType, IntegerType, StringType, BooleanType, FloatType\n",
    "from pyspark.sql.functions import expr, when, col, upper, regexp_replace, round, year, current_date, concat, lit, initcap, avg \n",
    "\n",
    "def sellers_transformation(sellers_df):\n",
    "    # changing the data types of columns\n",
    "    sellers_df = sellers_df \\\n",
    "    .withColumn(\"nbsellers\", col(\"nbsellers\").cast(IntegerType())) \\\n",
    "    .withColumn(\"meanproductssold\", col(\"meanproductssold\").cast(DecimalType(10, 2))) \\\n",
    "    .withColumn(\"meanproductslisted\", col(\"meanproductslisted\").cast(DecimalType(10, 2))) \\\n",
    "    .withColumn(\"meansellerpassrate\", col(\"meansellerpassrate\").cast(DecimalType(10, 2))) \\\n",
    "    .withColumn(\"totalproductssold\", col(\"totalproductssold\").cast(IntegerType())) \\\n",
    "    .withColumn(\"totalproductslisted\", col(\"totalproductslisted\").cast(IntegerType())) \\\n",
    "    .withColumn(\"meanproductsbought\", col(\"meanproductsbought\").cast(DecimalType(10, 2))) \\\n",
    "    .withColumn(\"meanproductswished\", col(\"meanproductswished\").cast(DecimalType(10, 2))) \\\n",
    "    .withColumn(\"meanproductsliked\", col(\"meanproductsliked\").cast(DecimalType(10, 2))) \\\n",
    "    .withColumn(\"totalbought\", col(\"totalbought\").cast(IntegerType())) \\\n",
    "    .withColumn(\"totalwished\", col(\"totalwished\").cast(IntegerType())) \\\n",
    "    .withColumn(\"totalproductsliked\", col(\"totalproductsliked\").cast(IntegerType())) \\\n",
    "    .withColumn(\"meanfollowers\", col(\"meanfollowers\").cast(DecimalType(10, 2))) \\\n",
    "    .withColumn(\"meanfollows\", col(\"meanfollows\").cast(DecimalType(10, 2))) \\\n",
    "    .withColumn(\"percentofappusers\", col(\"percentofappusers\").cast(DecimalType(10, 2))) \\\n",
    "    .withColumn(\"percentofiosusers\", col(\"percentofiosusers\").cast(DecimalType(10, 2))) \\\n",
    "    .withColumn(\"meanseniority\", col(\"meanseniority\").cast(DecimalType(10, 2)))\n",
    "\n",
    "    # Normalize country names and gender values\n",
    "    sellers_df = sellers_df.withColumn(\"country\", initcap(col(\"country\"))) \\\n",
    "                                                .withColumn(\"sex\", upper(col(\"sex\")))\n",
    "\n",
    "    #Add a column to categorize the number of sellers\n",
    "    sellers_df = sellers_df.withColumn(\"seller_size_category\", \n",
    "                               when(col(\"nbsellers\") < 500, \"Small\") \\\n",
    "                               .when((col(\"nbsellers\") >= 500) & (col(\"nbsellers\") < 2000), \"Medium\") \\\n",
    "                               .otherwise(\"Large\"))\n",
    "\n",
    "    # Calculate the mean products listed per seller as an indicator of seller activity\n",
    "    sellers_df = sellers_df.withColumn(\"mean_products_listed_per_seller\", \n",
    "                               round(col(\"totalproductslisted\") / col(\"nbsellers\"), 2)).withColumn(\"mean_products_listed_per_seller\", col(\"mean_products_listed_per_seller\").cast(DecimalType(10, 2)))\n",
    "    \n",
    "    # Identify markets with high seller pass rate\n",
    "    sellers_df = sellers_df.withColumn(\"high_seller_pass_rate\", \n",
    "                               when(col(\"meansellerpassrate\") > 0.75, \"High\") \\\n",
    "                               .otherwise(\"Normal\"))\n",
    "    \n",
    "    # mean of meansellerpassrate to replace the null value of column meansellerpassrate\n",
    "    mean_pass_rate = sellers_df.select(round(avg(col(\"meansellerpassrate\")),2)).collect()[0][0]\n",
    "\n",
    "    # sellers_df = sellers_df.fillna({\"meansellerpassrate\": mean_pass_rate})\n",
    "    sellers_df = sellers_df.withColumn(\"meansellerpassrate\", when(col(\"meansellerpassrate\").isNull(), mean_pass_rate).otherwise(col(\"meansellerpassrate\")))\n",
    "\n",
    "    return sellers_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2cdf8fbb-0ac6-4812-b978-3ff4797b70ff",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.types import DecimalType, IntegerType, StringType, BooleanType, FloatType\n",
    "from pyspark.sql.functions import expr, when, col, upper, regexp_replace, round, year, current_date, concat, lit, initcap, avg \n",
    "\n",
    "def countries_transformation(countries_df):\n",
    "\n",
    "    # changing the datatypes of columns\n",
    "    countries_df = countries_df \\\n",
    "    .withColumn(\"sellers\", col(\"sellers\").cast(IntegerType())) \\\n",
    "    .withColumn(\"topsellers\", col(\"topsellers\").cast(IntegerType())) \\\n",
    "    .withColumn(\"topsellerratio\", col(\"topsellerratio\").cast(DecimalType(10, 2))) \\\n",
    "    .withColumn(\"femalesellersratio\", col(\"femalesellersratio\").cast(DecimalType(10, 2))) \\\n",
    "    .withColumn(\"topfemalesellersratio\", col(\"topfemalesellersratio\").cast(DecimalType(10, 2))) \\\n",
    "    .withColumn(\"femalesellers\", col(\"femalesellers\").cast(IntegerType())) \\\n",
    "    .withColumn(\"malesellers\", col(\"malesellers\").cast(IntegerType())) \\\n",
    "    .withColumn(\"topfemalesellers\", col(\"topfemalesellers\").cast(IntegerType())) \\\n",
    "    .withColumn(\"topmalesellers\", col(\"topmalesellers\").cast(IntegerType())) \\\n",
    "    .withColumn(\"countrysoldratio\", col(\"countrysoldratio\").cast(DecimalType(10, 2))) \\\n",
    "    .withColumn(\"bestsoldratio\", col(\"bestsoldratio\").cast(DecimalType(10, 2))) \\\n",
    "    .withColumn(\"toptotalproductssold\", col(\"toptotalproductssold\").cast(IntegerType())) \\\n",
    "    .withColumn(\"totalproductssold\", col(\"totalproductssold\").cast(IntegerType())) \\\n",
    "    .withColumn(\"toptotalproductslisted\", col(\"toptotalproductslisted\").cast(IntegerType())) \\\n",
    "    .withColumn(\"totalproductslisted\", col(\"totalproductslisted\").cast(IntegerType())) \\\n",
    "    .withColumn(\"topmeanproductssold\", col(\"topmeanproductssold\").cast(DecimalType(10, 2))) \\\n",
    "    .withColumn(\"topmeanproductslisted\", col(\"topmeanproductslisted\").cast(DecimalType(10, 2))) \\\n",
    "    .withColumn(\"meanproductssold\", col(\"meanproductssold\").cast(DecimalType(10, 2))) \\\n",
    "    .withColumn(\"meanproductslisted\", col(\"meanproductslisted\").cast(DecimalType(10, 2))) \\\n",
    "    .withColumn(\"meanofflinedays\", col(\"meanofflinedays\").cast(DecimalType(10, 2))) \\\n",
    "    .withColumn(\"topmeanofflinedays\", col(\"topmeanofflinedays\").cast(DecimalType(10, 2))) \\\n",
    "    .withColumn(\"meanfollowers\", col(\"meanfollowers\").cast(DecimalType(10, 2))) \\\n",
    "    .withColumn(\"meanfollowing\", col(\"meanfollowing\").cast(DecimalType(10, 2))) \\\n",
    "    .withColumn(\"topmeanfollowers\", col(\"topmeanfollowers\").cast(DecimalType(10, 2))) \\\n",
    "    .withColumn(\"topmeanfollowing\", col(\"topmeanfollowing\").cast(DecimalType(10, 2)))\n",
    "\n",
    "    # Normalize country names in countries table\n",
    "    countries_df = countries_df.withColumn(\"country\", initcap(col(\"country\")))\n",
    "\n",
    "    # Calculating the ratio of top sellers to total sellers\n",
    "    countries_df = countries_df.withColumn(\"top_seller_ratio\", \n",
    "                                        round(col(\"topsellers\") / col(\"sellers\"), 2)).withColumn(\"top_seller_ratio\", col(\"top_seller_ratio\").cast(DecimalType(10, 2)))\n",
    "\n",
    "    # countriesDF countries with a high ratio of female sellers\n",
    "    countries_df = countries_df.withColumn(\"high_female_seller_ratio\", \n",
    "                                        when(col(\"femalesellersratio\") > 0.5, True).otherwise(False))\n",
    "\n",
    "    # Adding a performance indicator based on the sold/listed ratio\n",
    "    countries_df = countries_df.withColumn(\"performance_indicator\", \n",
    "                                        round(col(\"toptotalproductssold\") / (col(\"toptotalproductslisted\") + 1), 2)).withColumn(\"performance_indicator\", col(\"performance_indicator\").cast(DecimalType(10, 2)))\n",
    "\n",
    "    # Flag countries with exceptionally high performance\n",
    "    performance_threshold = 0.8\n",
    "    countries_df = countries_df.withColumn(\"high_performance\", \n",
    "                                        when(col(\"performance_indicator\") > performance_threshold, True).otherwise(False))\n",
    "\n",
    "    countries_df = countries_df.withColumn(\"activity_level\",\n",
    "                                       when(col(\"meanofflinedays\") < 30, \"Highly Active\")\n",
    "                                       .when((col(\"meanofflinedays\") >= 30) & (col(\"meanofflinedays\") < 60), \"Moderately Active\")\n",
    "                                       .otherwise(\"Low Activity\"))\n",
    "    \n",
    "    return countries_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "6092e3e0-e4de-49a4-a775-d860240c20ac",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def select_transformation(transformation_type, df):\n",
    "    if transformation_type == \"Ecommerce.users\":\n",
    "        transformed_df = users_transformation(df)\n",
    "    elif transformation_type == \"Ecommerce.buyers\":\n",
    "        transformed_df = buyers_transformation(df)\n",
    "    elif transformation_type == \"Ecommerce.sellers\":\n",
    "        transformed_df = sellers_transformation(df)\n",
    "    elif transformation_type == \"Ecommerce.countries\":\n",
    "        transformed_df = countries_transformation(df)\n",
    "    else:\n",
    "        dbutils.notebook.exit(\"Error: Invalid Transformation Type not mentioned\")\n",
    "\n",
    "    # Save the transformed DataFrame to the table\n",
    "    transformed_df.write.mode(\"overwrite\").saveAsTable(f\"{silver_schema}.{silver_table}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "b63a344a-3793-47b3-960d-1a94739ace64",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "select_transformation(transformation_type, df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "f3f477bb-0c60-42a3-ba5f-0a554717d4c4",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import count\n",
    "dbutils.notebook.exit([df.count()])"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "environmentMetadata": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "silver_transformation_ingestion_tables",
   "widgets": {
    "bronze_schema": {
     "currentValue": "",
     "nuid": "0e6b6302-2ccc-498c-a1ed-69fd1008b081",
     "typedWidgetInfo": {
      "autoCreated": false,
      "defaultValue": "",
      "label": null,
      "name": "bronze_schema",
      "options": {
       "validationRegex": null,
       "widgetDisplayType": "Text"
      },
      "parameterDataType": "String"
     },
     "widgetInfo": {
      "defaultValue": "",
      "label": null,
      "name": "bronze_schema",
      "options": {
       "autoCreated": null,
       "validationRegex": null,
       "widgetType": "text"
      },
      "widgetType": "text"
     }
    },
    "bronze_table": {
     "currentValue": "",
     "nuid": "c5be9fdf-02b5-4971-9a2b-50631b463a8e",
     "typedWidgetInfo": {
      "autoCreated": false,
      "defaultValue": "",
      "label": null,
      "name": "bronze_table",
      "options": {
       "validationRegex": null,
       "widgetDisplayType": "Text"
      },
      "parameterDataType": "String"
     },
     "widgetInfo": {
      "defaultValue": "",
      "label": null,
      "name": "bronze_table",
      "options": {
       "autoCreated": null,
       "validationRegex": null,
       "widgetType": "text"
      },
      "widgetType": "text"
     }
    },
    "env": {
     "currentValue": "",
     "nuid": "acfbc44d-6d7f-4514-b106-650637ba7f15",
     "typedWidgetInfo": {
      "autoCreated": false,
      "defaultValue": "",
      "label": null,
      "name": "env",
      "options": {
       "validationRegex": null,
       "widgetDisplayType": "Text"
      },
      "parameterDataType": "String"
     },
     "widgetInfo": {
      "defaultValue": "",
      "label": null,
      "name": "env",
      "options": {
       "autoCreated": null,
       "validationRegex": null,
       "widgetType": "text"
      },
      "widgetType": "text"
     }
    },
    "loadID": {
     "currentValue": "",
     "nuid": "6fb22bbe-4ed5-4b85-8e5e-fda7550b1757",
     "typedWidgetInfo": {
      "autoCreated": false,
      "defaultValue": "",
      "label": null,
      "name": "loadID",
      "options": {
       "validationRegex": null,
       "widgetDisplayType": "Text"
      },
      "parameterDataType": "String"
     },
     "widgetInfo": {
      "defaultValue": "",
      "label": null,
      "name": "loadID",
      "options": {
       "autoCreated": null,
       "validationRegex": null,
       "widgetType": "text"
      },
      "widgetType": "text"
     }
    },
    "silver_schema": {
     "currentValue": "",
     "nuid": "7cf04ac0-79b8-44fc-9f76-75721742f9d3",
     "typedWidgetInfo": {
      "autoCreated": false,
      "defaultValue": "",
      "label": null,
      "name": "silver_schema",
      "options": {
       "validationRegex": null,
       "widgetDisplayType": "Text"
      },
      "parameterDataType": "String"
     },
     "widgetInfo": {
      "defaultValue": "",
      "label": null,
      "name": "silver_schema",
      "options": {
       "autoCreated": null,
       "validationRegex": null,
       "widgetType": "text"
      },
      "widgetType": "text"
     }
    },
    "silver_table": {
     "currentValue": "",
     "nuid": "d619139a-032c-4c81-a4e8-a3a405d80ae6",
     "typedWidgetInfo": {
      "autoCreated": false,
      "defaultValue": "",
      "label": null,
      "name": "silver_table",
      "options": {
       "validationRegex": null,
       "widgetDisplayType": "Text"
      },
      "parameterDataType": "String"
     },
     "widgetInfo": {
      "defaultValue": "",
      "label": null,
      "name": "silver_table",
      "options": {
       "autoCreated": null,
       "validationRegex": null,
       "widgetType": "text"
      },
      "widgetType": "text"
     }
    },
    "transformation_type": {
     "currentValue": "",
     "nuid": "2bcd0fec-d161-421a-b739-fb2067a970c2",
     "typedWidgetInfo": {
      "autoCreated": false,
      "defaultValue": "",
      "label": null,
      "name": "transformation_type",
      "options": {
       "validationRegex": null,
       "widgetDisplayType": "Text"
      },
      "parameterDataType": "String"
     },
     "widgetInfo": {
      "defaultValue": "",
      "label": null,
      "name": "transformation_type",
      "options": {
       "autoCreated": null,
       "validationRegex": null,
       "widgetType": "text"
      },
      "widgetType": "text"
     }
    }
   }
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
